# 2019 Jon Reus
#
"""Runs the training of the TACOTRON-2 two-part model"""

import argparse
import json
import os

import tensorflow as tf

from trainer.hparams import hparams
import trainer.preprocess as preprocess
import trainer.train as train


if __name__ == '__main__':
    PARSER = argparse.ArgumentParser()
    # INPUT ARGUMENTS FOR PREPROCESSOR
    PARSER.add_argument('--datasetdir', default='', help='GCS file or local paths to training data in LJSpeech or M-AILABS format')
    PARSER.add_argument('--datasetformat', default='LJSpeech-Mini')
    PARSER.add_argument('--hparams', default='', help='Hyperparameter overrides hparams.py as a comma-separated list of name=value pairs')
    PARSER.add_argument('--preprocess', default=True, type=bool, help='Set this to false to skip preprocessing step')
    PARSER.add_argument('--preprocess-output-dir', default='preprocessed_data', help='Output directory for preprocessed data.')
    PARSER.add_argument('--language', default='en_US')
    PARSER.add_argument('--voice', default='female')
    PARSER.add_argument('--reader', default='mary_ann')
    PARSER.add_argument('--merge-books', default='False')
    PARSER.add_argument('--book', default='northandsouth')
    PARSER.add_argument('--output', default='training_data')
    PARSER.add_argument('--n_jobs', type=int, default=os.cpu_count(), help='Optional, number of worker process to parallelize across')
    # INPUT ARGUMENTS FOR TRAINING
    PARSER.add_argument('--tacotron-input-dir', default='', help='By default uses the directory in --preprocess-output-dir and looks for train.txt inside that directory.')
    PARSER.add_argument('--output-dir', help='Name of output directory, contains logs, synthesized mel spectrograms and trained model', default='output')
    PARSER.add_argument('--jobname', help='Name of this training job, was --name', default='')
    PARSER.add_argument('--wavenet-input-dir', default='', help='Location of metadata and training files for wavenet model. The program looks for the map.txt file generated by the synthesize step, in /gta/map.txt - by default this will be equal to --output-dir')
    PARSER.add_argument('--modeltype', help='Was --model', default='Tacotron-2')
    PARSER.add_argument('--mode', default='synthesis', help='mode for synthesis of tacotron after training')
    PARSER.add_argument('--GTA', default='True', help='Ground truth aligned synthesis, defaults to True, only considered in Tacotron synthesis mode')
    PARSER.add_argument('--restore', type=bool, default=True, help='Set this to False to do a fresh training')
    # These step numbers and intervals probably need to be a couple borders
    #  of magnitude higher (see original train.py call)
    PARSER.add_argument('--summary_interval', type=int, default=15,
    help='Steps between running summary ops')
    PARSER.add_argument('--embedding_interval', type=int, default=10,
    help='Steps between updating embeddings projection visualization')
    PARSER.add_argument('--checkpoint_interval', type=int, default=20,
    help='Steps between writing checkpoints')
    PARSER.add_argument('--eval_interval', type=int, default=10,
    help='Steps between eval on test data')
    PARSER.add_argument('--tacotron_train_steps', type=int, default=40, help='total number of tacotron training steps')
    PARSER.add_argument('--wavenet_train_steps', type=int, default=40, help='total number of wavenet training steps')
    PARSER.add_argument('--tf_log_level', type=int, default=1, help='Tensorflow C++ log level.')
    PARSER.add_argument('--verbosity', choices=['DEBUG', 'ERROR', 'FATAL', 'INFO', 'WARN'], default='INFO')
    PARSER.add_argument('--slack_url', default=None, help='slack webhook notification destination link')

    args = PARSER.parse_args()

    if args.tacotron_input_dir == '':
        args.tacotron_input_dir = args.preprocess_output_dir
    if args.wavenet_input_dir == '':
        args.wavenet_input_dir = args.output_dir

    # Set python level verbosity
    tf.logging.set_verbosity(args.verbosity)
    # Suppress C++ level warnings.
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

    # PREPROCESSING
    if args.preprocess is True:
        print('initializing preprocessing..')
        modified_hp = hparams.parse(args.hparams)
        assert args.merge_books in ('False', 'True')
        preprocess.run_preprocess(args, modified_hp)

    # MODEL TRAINING
    accepted_models = ['Tacotron', 'WaveNet', 'Tacotron-2']
    if args.modeltype not in accepted_models:
        raise ValueError('please enter a valid model to train: {}'.format(accepted_models))
    logs_dir, hparams = train.prepare_run(args)
    if args.modeltype == 'Tacotron':
        train.tacotron_train(args, logs_dir, hparams)
    elif args.modeltype == 'WaveNet':
        train.wavenet_train(args, logs_dir, hparams, args.wavenet_input_dir)
    elif args.modeltype == 'Tacotron-2':
        train.train(args, logs_dir, hparams)
    else:
        raise ValueError('Model provided {} unknown! {}'.format(args.modeltype, accepted_models))
